# Data cleaning

```{r}
library(haven)
library(knitr)
library(janitor)
library(here)
library(labelled)
library(countrycode)
library(tidyverse)
```

## Gallup

```{r gallup-codebook}
# Understand variables & values
# Codes NOTE 1: yes 2: no!
read_spss(
  "data-raw/Gallup/The_Gallup_042722.sav",
  n_max = 1,
  col_select = c(
    WPID, WP1219,
    # WP1220,  # Age
    WP16,
    WP60, WP61, WP63, WP65, WP67,
    WP68, WP69, WP70, WP71, WP74
  )
) %>%
  generate_dictionary()
```

```{r gallup-clean}
# First liberate the data from the slow SPSS file and save to disk
gwp_path <- here("data-raw/Gallup/gwp-processed.rds")
if (!file.exists(gwp_path)) {
  gwp <- read_spss(
    here("data-raw/Gallup/The_Gallup_042722.sav"),
    col_select = c(
      YEAR_CALENDAR,
      COUNTRYNEW,
      WPID, WP1220, WP1219,
      WP16,
      WP60, WP61, WP63, WP65, WP67,
      WP68, WP69, WP70, WP71, WP74
    )
  )
  
  # Get rid of SPSS attributes
  gwp <- gwp %>%
    zap_labels() %>%
    zap_label() %>%
    zap_widths() %>%
    zap_formats()
  
  # Save into a good format
  write_rds(gwp, gwp_path)
} else {
  gwp <- read_rds(gwp_path)
}

# Rename and recode variables
gwp <- gwp %>%
  clean_names() %>%
  transmute(
    country = countrynew,
    year = year_calendar,
    id = wpid,
    sex = factor(wp1219, levels = c(2, 1), labels = c("Female", "Male")),
    age = wp1220,
    # Don't know, refused, and missing values
    Life_satisfaction = if_else(between(wp16, 0, 10), wp16, NaN),
    across(wp60:wp74, ~ if_else(between(., 1, 2), ., NaN)),
    # Also reverse the weird 1: yes 2: no coding here
    across(wp60:wp74, ~ 3 - .)
  )

# Scale scores note rescaling
gwp <- gwp %>%
  mutate(
    Life_satisfaction = Life_satisfaction / 10,
    Negative_experiences =
      rowMeans(select(., wp68:wp74), na.rm = TRUE) - 1,
    Positive_experiences =
      rowMeans(select(., wp60:wp67), na.rm = TRUE) - 1
  ) %>%
  select(-c(wp60:wp74))

# Categorize ages
gwp <- gwp %>%
  mutate(
    age = factor(if_else(age <= 34, "13-34", "35+"))
  )

# Some age values are missing, drop those
gwp <- drop_na(gwp, age, sex)

# Include only years in fb data
gwp <- gwp %>% 
  filter(between(year, 2008, 2019))
```


```{r gallup-summarise}
gwp <- gwp %>%
  pivot_longer(
    c(
      Life_satisfaction,
      Negative_experiences,
      Positive_experiences
    ),
    names_to = "outcome", values_to = "val"
  ) %>%
  drop_na(val) %>% 
  group_by(country, year, sex, age, outcome) %>%
  summarise(
    n = n(),
    se = sd(val, na.rm = TRUE) / sqrt(n),
    val = mean(val, na.rm = TRUE)
  ) %>%
  ungroup()

# Note that if there is no response variance, SE will be zero, and if there is only 1 response, SE will be NA. Here we fix those by assigning them the maximum SE (0.5)
gwp <- gwp %>% 
  mutate(
    se = if_else(is.na(se) | se == 0, 0.5, se)
  )
```

```{r gwp-harmonise-countries}
# We can see that this would result in North Cyprus being lumped with Cyprus so we need to replace the name before harmonising

# Harmonise old names and replace only if harmonised name found
gwp <- gwp %>%
  mutate(
    country_harmonised = countryname(
      country,
      destination = "cldr.short.en"
    )
  ) %>%
  # This picks the harmonised name if exists, otherwise original name
  # Prevent north cyprus from becoming cyprus
  mutate(
    country_harmonised = ifelse(
      country == "Northern Cyprus",
      "Northern Cyprus",
      country_harmonised
    )
  ) %>%
  mutate(country = coalesce(country_harmonised, country)) %>%
  select(-country_harmonised)
```

Limit to countries in FB data

```{r}
fb_countries <- c(
  'Argentina', 'Armenia', 'Australia', 'Austria', 'Bangladesh', 'Belgium', 'Bolivia', 'Bosnia', 'Brazil', 'Bulgaria', 'Costa Rica', 'Croatia', 'Cyprus', 'Denmark', 'Dominican Republic', 'Ecuador', 'Egypt', 'El Salvador', 'Finland', 'France', 'Germany', 'Greece', 'Guatemala', 'Haiti', 'Honduras', 'Hungary', 'India', 'Iraq', 'Ireland', 'Israel', 'Italy', 'Japan', 'Jordan', 'Kenya', 'Libya', 'Lithuania', 'Malawi', 'Malaysia', 'Mexico', 'Morocco', 'Mozambique', 'Netherlands', 'New Zealand', 'Nicaragua', 'Nigeria', 'North Macedonia', 'Norway', 'Pakistan', 'Panama', 'Paraguay', 'Peru', 'Poland', 'Portugal', 'Puerto Rico', 'Qatar', 'Serbia', 'Slovakia', 'Slovenia', 'South Africa', 'Spain', 'Sri Lanka', 'Sweden', 'Switzerland', 'Taiwan', 'Thailand', 'Tunisia', 'Turkey', 'UK', 'United Arab Emirates', 'Uruguay', 'US', 'Venezuela'
)
gwp <- gwp %>% 
  filter(country %in% fb_countries)
```

### Synthetic GWP data

Create synthetic GWP data.

```{r mock-gwp-data}
gwp_mock_path <- here("data/gwp-SYNTHETIC.rds")
if (!file.exists(gwp_mock_path)) {
  library(synthpop)
  gwp_syn <- gwp %>% 
    drop_na()
  gwp_syn <- syn(
    gwp_syn, 
    method = c("", "", "", "", "", "normrank", "normrank", "normrank"),
    maxfaclevels = 72
  )
  gwp_syn <- tibble(gwp_syn$syn)
  saveRDS(gwp_syn, gwp_mock_path)
}
```

## Population

From <https://population.un.org/wpp/Download/Standard/Population/>.

```{r}
library(readxl)
pop <- read_excel(
  "data/WPP2022_POP_F01_1_POPULATION_SINGLE_AGE_BOTH_SEXES.xlsx", 
  sheet = 1, 
  skip = 16,
  col_types = "text",
  .name_repair = make_clean_names
  )
pop <- pop %>% 
  drop_na(iso3_alpha_code) %>% 
  select(
    iso3_alpha_code, year, starts_with("x")
  ) %>% 
  mutate(
    country = countrycode(
      iso3_alpha_code, 
      origin = "iso3c", 
      destination = "cldr.short.en"
    )
  )
pop <- pop %>% 
  filter(
    country %in% fb_countries,
    between(year, 2008, 2019)
  ) %>% 
  pivot_longer(
    starts_with("x"), 
    names_to = "age",
    values_to = "pop",
    names_transform = ~str_remove(., "x") %>% as.numeric, 
    values_transform = ~ as.numeric(.) * 1000
  ) %>% 
  filter(between(age, 13, 100)) %>% 
  mutate(
    age = cut(age, c(0, 34.5, 1000), labels = c("13-34", "35+"))
  )
pop <- pop %>% 
  mutate(year = as.numeric(year)) %>% 
  group_by(country, year, age) %>% 
  summarise(pop = sum(pop)) %>% 
  ungroup()
```

## Synthetic Facebook data

Here we create simple time trend data that can be used for reproducing the computations when the actual Facebook data is not available. It does not represent any statistical properties of the Facebook data and is created simply to help run the computations.

```{r}
fb_mock_path <- here("data/fb-SYNTHETIC.rds")
if (!file.exists(fb_mock_path)) {
  library(extraDistr)
  set.seed(999)
  slopes <- distinct(pop, country) %>% 
    mutate(slope = rnorm(72, 0.75, 0.1))
  fb_syn <- pop %>% 
    left_join(slopes) %>% 
    rowwise() %>% 
    mutate(
      dau = rprop(1, 50, plogis(-4 + slope*(year-2008))),
      mau = rprop(1, 100, plogis(-5 + slope*(year-2008)))
    )
  saveRDS(fb_syn, fb_mock_path)
}
```


### Save

```{r gallup-save}
# Save
dir.create("data", FALSE)
write_rds(gwp, "data/gwp.rds")
write_rds(pop, "data/population.rds")
```
